{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd8e69c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350e1a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9c2d41",
   "metadata": {},
   "source": [
    "## Generate image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35991272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52501 files belonging to 8 classes.\n",
      "Using 42001 files for training.\n",
      "Using 10500 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"dataset/Training\",\n",
    "    validation_split = 0.2,\n",
    "    subset = \"both\",\n",
    "    seed = 1337,\n",
    "    image_size = (180, 180),\n",
    "    batch_size = 128,\n",
    ")\n",
    "\n",
    "#test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#   \"dataset/ALL/Testing\",\n",
    "#    image_size = (180, 180),\n",
    "#    batch_size = 128,\n",
    "#    shuffle = False\n",
    "#)\n",
    "\n",
    "class_names = os.listdir(\"dataset/Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b0c245",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b6c16",
   "metadata": {},
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d9473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ce6be",
   "metadata": {},
   "source": [
    "## Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9bef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(180, 180, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29a4f2",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827b96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d201c",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db0199fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 180, 180, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7744)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               991360    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 997,480\n",
      "Trainable params: 997,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca88ce6",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4dfdff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "329/329 [==============================] - 240s 721ms/step - loss: 0.2878 - accuracy: 0.8970 - val_loss: 0.1422 - val_accuracy: 0.9523\n",
      "Epoch 2/10\n",
      "329/329 [==============================] - 180s 542ms/step - loss: 0.0688 - accuracy: 0.9780 - val_loss: 0.0519 - val_accuracy: 0.9807\n",
      "Epoch 3/10\n",
      "329/329 [==============================] - 169s 510ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.0428 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "329/329 [==============================] - 177s 536ms/step - loss: 0.0617 - accuracy: 0.9814 - val_loss: 0.0349 - val_accuracy: 0.9880\n",
      "Epoch 5/10\n",
      "329/329 [==============================] - 177s 533ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0344 - val_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "329/329 [==============================] - 177s 535ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0198 - val_accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "329/329 [==============================] - 177s 535ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.2568 - val_accuracy: 0.9409\n",
      "Epoch 8/10\n",
      "329/329 [==============================] - 179s 538ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.0322 - val_accuracy: 0.9899\n",
      "Epoch 9/10\n",
      "329/329 [==============================] - 177s 535ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0283 - val_accuracy: 0.9903\n",
      "Epoch 10/10\n",
      "329/329 [==============================] - 177s 533ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0178 - val_accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "cnn_model = model.fit(train_ds, validation_data = val_ds, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7e7a6",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a5ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/general_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833a2155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 432ms/step\n",
      "1\n",
      "This image is most likely a Kidney Cancer with a 100.00 percent confidence\n"
     ]
    }
   ],
   "source": [
    "image_url = \"dataset/Testing/kidney/Testing/kidney_normal/kidney_normal_2457.jpg\"\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    image_url, target_size = (180, 180)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(len(predictions))\n",
    "print(\"This image is most likely a {} with a {:.2f} percent confidence\"\n",
    "      .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d30d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
